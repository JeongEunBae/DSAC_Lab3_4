{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TI5-Fx_zPO0Y"
   },
   "source": [
    "네이버영화평점\n",
    "==\n",
    "- 감성분석\n",
    "- 네이버 영화평점 (Naver sentiment movie corpus v.1.0) 데이터(https://github.com/e9t/nsmc)\n",
    "- 영화 리뷰 20만건이 저장됨. 각 평가 데이터는 0(부정), 1(긍정)으로 label 됨.\n",
    "\n",
    "### 한글 자연어 처리\n",
    "- KoNLPy(“코엔엘파이”라고 읽습니다)는 한국어 정보처리를 위한 파이썬 패키지입니다.\n",
    "- konlpy 패키지에서 제공하는 Twitter라는 문서 분석 라이브러리 사용 (트위터 분석 뿐 아니라 한글 텍스트 \n",
    "  처리도 가능)\n",
    "- colab 사용 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZNLuzYoPO0k"
   },
   "source": [
    "# 로지스틱회귀를 이용한 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "Q8ZDSK7xQfmD",
    "outputId": "d0f24269-7c5c-4ef7-c364-769ef735adcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\rta_note\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: JPype1>=0.5.7 in c:\\users\\rta_note\\anaconda3\\lib\\site-packages (from konlpy) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curl:\n",
    "# curl is a tool to transfer data from or to a server, using one of the supported protocols (HTTP, HTTPS, FTP,\n",
    "# FTPS, SCP, SFTP, TFTP, DICT, TELNET, LDAP or FILE). The command is designed to work without user interaction.\n",
    "# \n",
    "# curl -L : (HTTP/HTTPS) If the server reports that the requested page has moved to a different location \n",
    "# (indicated with a Location: header and a 3XX response code), this option will make curl redo the request \n",
    "# on the new place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "Cr1Rds4XQn2N",
    "outputId": "bb49b694-235a-4c1c-d1ec-79f2ac0977ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   152  100   152    0     0    136      0  0:00:01  0:00:01 --:--:--   138\n",
      "100   152  100   152    0     0    136      0  0:00:01  0:00:01 --:--:--   138\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  8 14.0M    8 1262k    0     0   406k      0  0:00:35  0:00:03  0:00:32 1922k\n",
      " 25 14.0M   25 3710k    0     0   902k      0  0:00:15  0:00:04  0:00:11 2239k\n",
      " 46 14.0M   46 6734k    0     0  1317k      0  0:00:10  0:00:05  0:00:05 2534k\n",
      " 66 14.0M   66 9662k    0     0  1581k      0  0:00:09  0:00:06  0:00:03 2642k\n",
      " 82 14.0M   82 11.6M    0     0  1676k      0  0:00:08  0:00:07  0:00:01 2559k\n",
      "100 14.0M  100 14.0M    0     0  1786k      0  0:00:08  0:00:08 --:--:-- 2650k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   151  100   151    0     0    136      0  0:00:01  0:00:01 --:--:--   136\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      " 16 4827k   16  814k    0     0   283k      0  0:00:17  0:00:02  0:00:15  827k\n",
      " 67 4827k   67 3278k    0     0   846k      0  0:00:05  0:00:03  0:00:02 1651k\n",
      "100 4827k  100 4827k    0     0  1080k      0  0:00:04  0:00:04 --:--:-- 1872k\n"
     ]
    }
   ],
   "source": [
    "# 네이버 영화 평점 데이터 다운로드\n",
    "!curl -L https://bit.ly/2X9Owwr -o ratings_train.txt\n",
    "!curl -L https://bit.ly/2WuLd5I -o ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoNLPy(“코엔엘파이”라고 읽습니다)는 한국어 정보처리를 위한 파이썬 패키지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: 264E-2F1C\n",
      "\n",
      " C:\\Users\\rta_note\\Desktop\\Lab_M34 디렉터리\n",
      "\n",
      "2019-09-06  오후 03:13    <DIR>          .\n",
      "2019-09-06  오후 03:13    <DIR>          ..\n",
      "2019-08-31  오후 02:10    <DIR>          .ipynb_checkpoints\n",
      "2019-07-20  오후 01:21             3,258 baseline-script.csv\n",
      "2019-07-21  오후 07:28           659,240 bike_train.csv\n",
      "2019-07-20  오후 01:17             5,221 decision-tree.dot\n",
      "2019-08-05  오후 06:13             8,587 digit2.png\n",
      "2019-08-05  오후 06:20             9,344 digit2_2.png\n",
      "2019-08-05  오후 06:13             7,431 digit9.png\n",
      "2019-08-05  오후 06:14             8,408 digit9_2.png\n",
      "2019-08-05  오후 06:21            33,284 digit9_3.png\n",
      "2019-08-05  오후 06:21            24,365 digit9_4.png\n",
      "2019-08-05  오후 07:09             6,067 digits.pkl\n",
      "2019-08-05  오후 05:02         5,955,180 face-detect.png\n",
      "2019-08-05  오후 05:03            58,609 face-pickup.png\n",
      "2019-08-05  오후 05:00         1,774,696 families.jpg\n",
      "2019-07-20  오전 10:33             8,917 gg_34_kNN.ipynb\n",
      "2019-07-20  오후 01:01           142,693 gg_35_결정트리_붓꽃유방암.ipynb\n",
      "2019-07-20  오후 01:32           160,079 gg_36_결정트리_타이타닉.ipynb\n",
      "2019-07-27  오후 12:00            92,705 gg_37_랜덤포레스트.ipynb\n",
      "2019-07-27  오후 02:29           310,862 gg_38_자전거대여예측.ipynb\n",
      "2019-08-02  오후 04:25            91,843 gg_39_SVM.ipynb\n",
      "2019-08-03  오후 02:51           124,713 gg_40_분류성능.ipynb\n",
      "2019-08-03  오후 03:39            55,621 gg_41_분류성능비교_포도주_ROC.ipynb\n",
      "2019-08-03  오후 04:19            82,619 gg_42_주성분분석_tSNE_유방암.ipynb\n",
      "2019-06-07  오후 06:00           669,639 gg_43_선형모델규제.ipynb\n",
      "2019-08-05  오후 05:05         1,690,486 gg_44_opencv_intro.ipynb\n",
      "2019-08-05  오후 07:19           184,948 gg_45_opencv_digit.ipynb\n",
      "2019-08-07  오후 08:18           235,317 gg_46_object_detect.ipynb\n",
      "2019-04-29  오전 04:21               439 gg_47_save_video.py\n",
      "2019-04-29  오전 04:21             1,193 gg_48_diff_camera.py\n",
      "2019-04-29  오전 04:21               442 gg_49_red_camera.py\n",
      "2019-08-07  오후 08:45         5,023,739 gg_50_image_download.ipynb\n",
      "2019-09-05  오후 06:33           102,878 gg_51_뉴스기사.ipynb\n",
      "2019-09-06  오후 03:06            64,474 gg_52_스팸분류.ipynb\n",
      "2019-09-06  오후 03:13            37,387 gg_53_네이버영화평점.ipynb\n",
      "2019-06-01  오전 09:25            19,984 gg_54_단어벡터.ipynb\n",
      "2019-06-01  오전 09:50            11,559 gg_55_형태소_분석.ipynb\n",
      "2019-06-01  오전 11:16           130,443 gg_56_토픽모델링.ipynb\n",
      "2019-05-26  오후 05:14            11,877 gg_57_텐서플로우기초.ipynb\n",
      "2019-05-26  오후 05:17            12,919 gg_58_MNIST_텐서플로우.ipynb\n",
      "2019-06-07  오후 07:43            17,413 gg_59_MNIST_keras.ipynb\n",
      "2019-06-08  오후 04:12           255,667 gg_60_cats_and_dogs_keras.ipynb\n",
      "2019-06-08  오후 03:09           171,295 gg_61_cats_and_dogs_transfer.ipynb\n",
      "2019-06-01  오후 01:45            25,351 gg_62_네이버영화감성분석_신경망.ipynb\n",
      "2019-06-01  오후 06:40            12,806 gg_63_단어벡터_IMDB.ipynb\n",
      "2019-06-01  오후 06:46           121,206 gg_64_언어모델링.ipynb\n",
      "2019-06-02  오후 03:06           858,414 gg_65_시계열분석기초.ipynb\n",
      "2019-06-03  오후 10:03           191,528 gg_66_날씨시계열_RNN.ipynb\n",
      "2019-06-06  오전 12:06         1,042,080 gg_67_행동데이터분석.ipynb\n",
      "2019-06-06  오전 12:31            27,761 gg_68_yolo.ipynb\n",
      "2019-06-06  오전 12:58            11,840 gg_69_yolov3.ipynb\n",
      "2019-06-06  오전 12:57            23,446 gg_70_YOLO_YouTube.ipynb\n",
      "2019-08-05  오후 04:52           676,709 haar.xml\n",
      "2019-07-21  오후 06:42           172,346 hyperparam_cv.ipynb\n",
      "2019-08-07  오후 07:59           184,859 im-circle.png\n",
      "2019-08-07  오후 08:13           137,125 im-post.png\n",
      "2019-07-20  오후 12:30             1,040 iris.dot\n",
      "2019-07-27  오후 01:20           107,629 lab_gridsearchcv.ipynb\n",
      "2019-09-05  오후 05:20         1,832,194 news.xlsx\n",
      "2019-07-27  오후 01:18             3,258 op_rf.csv\n",
      "2019-08-05  오후 03:48         1,625,562 pool.jpg\n",
      "2019-08-05  오후 04:24         2,073,349 pool_2.jpg\n",
      "2019-09-06  오후 03:14         4,943,336 ratings_test.txt\n",
      "2019-09-06  오후 03:14        14,778,808 ratings_train.txt\n",
      "2019-09-05  오후 11:53           500,336 sms_spam.csv\n",
      "2019-07-20  오후 01:19             3,258 titanic_gender_submission.csv\n",
      "2019-07-20  오후 01:03            28,629 titanic_test.csv\n",
      "2019-07-20  오후 01:03            61,194 titanic_train.csv\n",
      "              66개 파일          47,709,905 바이트\n",
      "               3개 디렉터리  198,705,340,416 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "UqXWg0fAPO0l",
    "outputId": "72348974-30fa-47ae-d6d9-78db296e2315",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# import pickle\n",
    "# import os.path\n",
    "\n",
    "# 데이터 로드\n",
    "# keep_default_na: Whether or not to include the default NaN values when parsing the data\n",
    "# -> False: no strings will be parsed as NaN.\n",
    "\n",
    "df_train = pd.read_csv('ratings_train.txt', delimiter='\\t', keep_default_na=False)\n",
    "df_test = pd.read_csv('ratings_test.txt', delimiter='\\t', keep_default_na=False)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "id": "In_TH58BPO0q",
    "outputId": "33713e49-ecff-4f37-8330-9fcde95a310d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text_train, y_train = df_train['document'].as_matrix(), df_train['label'].as_matrix()\n",
    "# text_test, y_test = df_test['document'].as_matrix(), df_test['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, y_train = df_train['document'].values, df_train['label'].values\n",
    "text_test, y_test = df_test['document'].values, df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gy5fHajqPO0w"
   },
   "outputs": [],
   "source": [
    "def twitter_tokenizer(text):\n",
    "    return twitter_tag.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Q4ASh_pBPO0z",
    "outputId": "976141fc-0d54-40a4-c82e-6bdba308a02b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rta_note\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "ename": "JVMNotFoundException",
     "evalue": "No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJVMNotFoundException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0f8e983aa7ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtwitter_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtwitter_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mTwitter\u001b[1;34m(jvmpath)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvmpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misJVMStarted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mjvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_jvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0moktJavaPackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kr.lucypark.okt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\jvm.py\u001b[0m in \u001b[0;36minit_jvm\u001b[1;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mclasspath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolder_suffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mjvmpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjvmpath\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDefaultJVMPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# NOTE: Temporary patch for Issue #76. Erase when possible.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\jpype\\_core.py\u001b[0m in \u001b[0;36mgetDefaultJVMPath\u001b[1;34m()\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mfinder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinuxJVMFinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_jvm_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\jpype\\_jvmfinder.py\u001b[0m in \u001b[0;36mget_jvm_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m                                        \u001b[1;34m\"found. Try setting up the JAVA_HOME \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                                        \u001b[1;34m\"environment variable properly.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                                        .format(self._libfile))\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_from_java_home\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJVMNotFoundException\u001b[0m: No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly."
     ]
    }
   ],
   "source": [
    "twitter_tag = Twitter()\n",
    "\n",
    "cv = TfidfVectorizer(tokenizer=twitter_tokenizer, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "V7eeTvGHPO04",
    "outputId": "3cf378d9-d224-4b16-9533-636ff3bcbf2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "x_train = cv.fit_transform(text_train)\n",
    "x_test = cv.transform(text_test)\n",
    "result = lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qPsRbX4fUZCW",
    "outputId": "efc6386c-199c-44c0-d3dd-8bd50ee0d5f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22414"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "PKsL-coiPO08",
    "outputId": "e6bcef0f-c660-4568-8dae-c712c4326dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['기억나는게', '기억나는데', '기억나서', '기억나요', '기억나지', '기억난다', '기억남', '기억남는', '기억남는건', '기억상실증']\n"
     ]
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "print(feature_names[3000:3010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "-u3lCQXTPO0_",
    "outputId": "3086d24c-d225-472a-f623-604cbaad2d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 점수 :  0.88164\n",
      "테스트 데이터 점수 :  0.85088\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 점수 : \", result.score(x_train, y_train))\n",
    "print(\"테스트 데이터 점수 : \", result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsnrMwHXPO1E"
   },
   "source": [
    "# LSTM을 이용한 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8zebbzoPO1G",
    "outputId": "bce1b47f-8d93-4469-969a-7b111a47cecf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "text_data, y_data = df_data['document'].as_matrix(), df_data['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XY8nO_VWPO1L",
    "outputId": "39de55d2-2496-4da9-e603-1d4993044a23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "# 토큰 파서\n",
    "def twitter_tokenizer(text):\n",
    "    return twitter_tag.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1dR0Ql0PO1Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtlGfMtPPO1T"
   },
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(tokenizer=twitter_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNDwKtJHPO1V",
    "outputId": "d61c4c3e-297c-46fd-9961-7e9eeba31f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data.pickle\t X_test_2.pickle  X_train_1.pickle\r\n",
      "X_test_1.pickle  X_test.pickle\t  X_train_2.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4EgTHi-PO1b"
   },
   "outputs": [],
   "source": [
    "# Tfidf 생성과 저장 - 단 파일이 없을 때만 !!\n",
    "if not os.path.isfile(\"X_data.pickle\"): \n",
    "    print('file does not exists')\n",
    "    X_data = cv.fit_transform(text_data)\n",
    "    pickle.dump(X_train, open(\"X_data.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pviIJR6ZPO1e"
   },
   "outputs": [],
   "source": [
    "# 저장된 tfidf vector 데이터 읽기\n",
    "with open('X_data.pickle', 'rb') as f:\n",
    "    X_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpi1YvmdPO1g",
    "outputId": "c5d7e3a2-0637-460f-de43-42d67732ca26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 hjkim hjkim 24433014 Oct 28 18:39 X_data.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim  7782344 Oct 28 19:03 X_test_1.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim  5610600 Oct 28 18:56 X_test_2.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim  8170628 Oct 28 18:40 X_test.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim 23745856 Oct 28 19:02 X_train_1.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim 14084384 Oct 28 18:55 X_train_2.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTjdoWMoPO1l"
   },
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "Y_data = np_utils.to_categorical(y_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAPyi6uwPO1n"
   },
   "outputs": [],
   "source": [
    "X_train = X_data[:100000]\n",
    "X_test = X_data[100000:]\n",
    "\n",
    "Y_train = Y_data[:100000]\n",
    "Y_test = Y_data[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JI6yem-OPO1q"
   },
   "outputs": [],
   "source": [
    "max_words = 61070 \n",
    "nb_classes = 2\n",
    "batch_size = 1024\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYzxE1DIPO1u",
    "outputId": "39934207-5079-4add-f9a1-fa46d212e713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 104160)\n",
      "(50000, 104160)\n",
      "(100000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxUfYM-PPO1w",
    "outputId": "4eb78b25-9284-4123-f92c-b8c3f621ae36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1, 104160)\n",
      "(50000, 1, 104160)\n"
     ]
    }
   ],
   "source": [
    "# LSTM 학습을 위한 데이터 재배열 (Time step)\n",
    "X_train_rnn = X_train.A.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.A.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(X_train_rnn.shape)\n",
    "print(X_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_yPDRa0PO1z"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def build_LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzZ0Jpc0PO13",
    "outputId": "cace0460-c673-42e3-c0e4-0ffd2bb04ae0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 252s 3ms/step - loss: 0.5463 - acc: 0.7826\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 238s 2ms/step - loss: 0.2854 - acc: 0.8830\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 239s 2ms/step - loss: 0.2076 - acc: 0.9218\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - 238s 2ms/step - loss: 0.1604 - acc: 0.9420\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 239s 2ms/step - loss: 0.1293 - acc: 0.9543\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "with K.tf.device('/GPU:1'):\n",
    "    model_lstm = KerasClassifier(\n",
    "    build_fn=build_LSTM_model, \n",
    "    epochs=nb_epoch, \n",
    "    batch_size=batch_size)\n",
    "    \n",
    "    model_lstm.fit(X_train_rnn, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EzWAnPvPO16",
    "outputId": "10d3962f-3bc5-4bdb-97aa-d7997a7f52b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 셋 정답률 = 0.96941\n"
     ]
    }
   ],
   "source": [
    "y = model_lstm.predict(X_train_rnn)\n",
    "y_train = y_data[:100000]\n",
    "ac_score = metrics.accuracy_score(y_train, y)\n",
    "print(\"훈련 셋 정답률 =\", ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wEdCDE5PO19",
    "outputId": "2e5e080c-6a44-40d8-e437-20f138b46b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y :  [0 1 0 ... 0 1 1]\n",
      "Y_train[0] :  [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "y_train[0] :  [0 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# predict 함수는 예측 결과를 0 or 1로 출력하므로\n",
    "# 학습과정에서 사용한 Y_train, Y_test 변수로 정확도 측정이 안됨\n",
    "# Y_train, Y_test는 [0, 1], [1, 0]의 형태로 해당하는 감정 컬럼(class)은 1, 다른 컬럼은 0으로 표시됨\n",
    "# 초기 y_data에 저장된 값을 그대로 활용하여 정확도를 측정\n",
    "\n",
    "print(\"y : \", y)\n",
    "print(\"Y_train[0] : \", Y_train)\n",
    "print(\"y_train[0] : \", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIs-Hiv1PO2B",
    "outputId": "4bf68fb8-5a7c-48e9-f0d6-acb26e503a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정답률 = 0.83784\n"
     ]
    }
   ],
   "source": [
    "y = model_lstm.predict(X_test_rnn)\n",
    "y_test = y_data[100000:]\n",
    "ac_score = metrics.accuracy_score(y_test, y)\n",
    "print(\"테스트 셋 정답률 =\", ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrYzqO_PPO2D"
   },
   "source": [
    "## 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3\n",
       "0  0  1   2   3\n",
       "1  4  5   6   7\n",
       "2  8  9  10  11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(np.arange(12).reshape(3,4)); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rta_note\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.as_matrix()   # Convert the frame to its Numpy-array representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values       # using this is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rta_note\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 4, 8]), array([0, 4, 8]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].as_matrix(), df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gg_56_네이버영화평점",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
