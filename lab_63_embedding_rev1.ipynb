{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lab_63_embedding_rev1.ipynb","provenance":[{"file_id":"1vglMMavBgTKqscKfwZNdGa_b-oTwBaYU","timestamp":1604891467879}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/StillWork/c9/blob/master/gg_67_%EB%8B%A8%EC%96%B4%EB%B2%A1%ED%84%B0_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"2Pa94qBD7EKp"},"source":["# 단어 임베딩\n","### Embedding 계층을 사용하여 쉽게 만들 수 있다\n","- 정수 인덱스를 벡터로 매핑하는 딕셔너리 구조 (인덱스 크기, 벡터 크기)\n","- 학습 시키는 데이터에 따라 다른 임베딩이 만들어진다.\n","\n","### IMDB 영화 리뷰 데이터를 사용한 임베딩 예제\n","\n"]},{"cell_type":"code","metadata":{"id":"y8hRGgn85LtI","executionInfo":{"status":"ok","timestamp":1605959665422,"user_tz":-540,"elapsed":2673,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}}},"source":["from keras.models import Sequential\n","from keras.layers import Flatten, Dense, Embedding\n","import os, os.path\n","import zipfile\n","from keras.datasets import imdb\n","from keras import preprocessing\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LIZeMWh1AX2i"},"source":["- 10000 개의 단어만 사용하고, 각 문장에서는 뒤에서부터 20 개의 단어만 사용하겠음."]},{"cell_type":"code","metadata":{"id":"9Tu8xAnn_nGl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605959681250,"user_tz":-540,"elapsed":6112,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"61f8c63c-d52b-41b5-fda0-e8761d256f75"},"source":["max_features = 10000\n","maxlen = 20\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gXuG1WkZeq6L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605959961356,"user_tz":-540,"elapsed":642,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"14be93e4-e9c4-48a8-a2b7-fc3baf61835c"},"source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((25000,), (25000,), (25000,), (25000,))"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3AbuPD9rNde","executionInfo":{"status":"ok","timestamp":1605960101040,"user_tz":-540,"elapsed":664,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"e9c1a38d-2d50-4218-d71f-59a1d381d829"},"source":["y_train[:5]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"XEmlO1XkY2tZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605959727093,"user_tz":-540,"elapsed":1189,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"330c59bb-ef29-4882-cba1-8f4f3fb4ec62"},"source":["[len(x_train[i]) for i in range(10)]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[218, 189, 141, 550, 147, 43, 123, 562, 233, 130]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"zqzfqXMEY2tg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605959737749,"user_tz":-540,"elapsed":1120,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"5886fdff-6d8b-4b45-ecf0-850731c1c3f9"},"source":["# 각 문장이 몇개의 단어로 구성되어 있는지 확인\n","for i in range(10):\n","    print(len(x_train[i]))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["218\n","189\n","141\n","550\n","147\n","43\n","123\n","562\n","233\n","130\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J4w1ON5Z7SvH","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605959765718,"user_tz":-540,"elapsed":665,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"aa9f8552-fc46-4ba7-a83a-1cce30470214"},"source":["x_train[0:2]   # words tokenized and expressed by (word) numbers"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n","       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"blQtfwq4e3NP","executionInfo":{"status":"ok","timestamp":1605959794580,"user_tz":-540,"elapsed":685,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}}},"source":["# 마지막 20개의 단어들만 사용한다. -> 20개보다 적으면 똑같은 길이로 만들어 준다. padding position is 'post'\n","x_train_p=preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen, padding='post')\n","x_test_p=preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen, padding='post')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_WuOAkafd8M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605959797450,"user_tz":-540,"elapsed":653,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"75ae303b-9e02-4a24-b38c-851d18e2e8a4"},"source":["x_train_p[0:2]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n","         113,  103,   32,   15,   16, 5345,   19,  178,   32],\n","       [  23,    4, 1690,   15,   16,    4, 1355,    5,   28,    6,   52,\n","         154,  462,   33,   89,   78,  285,   16,  145,   95]],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"KD5dWA__fqO1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605960139016,"user_tz":-540,"elapsed":693,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"d3e1851f-80ca-4c1d-b5cb-95b76d058f54"},"source":["model = Sequential()\n","model.add(Embedding(10000, 8, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['acc'])\n","model.summary()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 20, 8)             80000     \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 160)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 161       \n","=================================================================\n","Total params: 80,161\n","Trainable params: 80,161\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LiMsP3C96RRg","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605960184230,"user_tz":-540,"elapsed":20397,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"1452e63f-ab28-45ff-c45b-e771f250b84f"},"source":["history = model.fit(x_train_p, y_train,\n","                    epochs=10, batch_size=32,\n","                    validation_split=0.2)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.6717 - acc: 0.6120 - val_loss: 0.6233 - val_acc: 0.6926\n","Epoch 2/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.5443 - acc: 0.7501 - val_loss: 0.5288 - val_acc: 0.7282\n","Epoch 3/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4627 - acc: 0.7886 - val_loss: 0.5028 - val_acc: 0.7430\n","Epoch 4/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4221 - acc: 0.8105 - val_loss: 0.4980 - val_acc: 0.7502\n","Epoch 5/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3948 - acc: 0.8253 - val_loss: 0.4958 - val_acc: 0.7556\n","Epoch 6/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3718 - acc: 0.8387 - val_loss: 0.4996 - val_acc: 0.7584\n","Epoch 7/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3513 - acc: 0.8507 - val_loss: 0.5060 - val_acc: 0.7522\n","Epoch 8/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3337 - acc: 0.8600 - val_loss: 0.5140 - val_acc: 0.7524\n","Epoch 9/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3158 - acc: 0.8699 - val_loss: 0.5206 - val_acc: 0.7476\n","Epoch 10/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.2993 - acc: 0.8791 - val_loss: 0.5281 - val_acc: 0.7466\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3NYmQslQ_Edk"},"source":["## 위의 결과는 20개의 단어만 고려한 것임\n","### 성능이 75% 정도 됨\n","- 각 단어를 독립적으로 다루었으며, 문장의 구성 정보를 고려하지 않음\n","- 문장의 구조 정보를 고려하려면 임베딩 층 위에 합성곱이나 순환신경망 층을 추가한다"]},{"cell_type":"markdown","metadata":{"id":"VNRUc-dA0i9C"},"source":["## RNN 추가"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrnA5C8y30oX","executionInfo":{"status":"ok","timestamp":1605963351002,"user_tz":-540,"elapsed":1088,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"3f287880-2eb3-44f4-9c24-d9a4db9b39bb"},"source":["x_train_p.shape"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000, 20)"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGNtU9Bz0idI","executionInfo":{"status":"ok","timestamp":1605964586684,"user_tz":-540,"elapsed":657,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"53df04ce-f847-4bbf-bcfa-93076f0b95bf"},"source":["from keras.models import Sequential\n","from keras.layers import SimpleRNN, Dense\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=10000, output_dim=8))\n","model.add(SimpleRNN(128))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['acc'])\n","model.summary()"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (None, None, 8)           80000     \n","_________________________________________________________________\n","simple_rnn_3 (SimpleRNN)     (None, 128)               17536     \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 128)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 97,665\n","Trainable params: 97,665\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqusSXm75Lun","executionInfo":{"status":"ok","timestamp":1605964886426,"user_tz":-540,"elapsed":142216,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"2aade0d5-105e-41f8-fbcc-5dc7851916b4"},"source":["history = model.fit(x_train_p, y_train,\n","                    epochs=20, batch_size=32,\n","                    validation_split=0.2)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.2366 - acc: 0.9054 - val_loss: 0.6656 - val_acc: 0.7322\n","Epoch 2/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.2135 - acc: 0.9142 - val_loss: 0.7111 - val_acc: 0.7404\n","Epoch 3/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.1929 - acc: 0.9262 - val_loss: 0.7477 - val_acc: 0.7168\n","Epoch 4/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.1761 - acc: 0.9305 - val_loss: 0.7536 - val_acc: 0.7054\n","Epoch 5/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.1596 - acc: 0.9385 - val_loss: 0.7384 - val_acc: 0.7302\n","Epoch 6/20\n","625/625 [==============================] - 7s 12ms/step - loss: 0.1452 - acc: 0.9440 - val_loss: 0.8054 - val_acc: 0.7122\n","Epoch 7/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.1330 - acc: 0.9502 - val_loss: 0.8328 - val_acc: 0.7230\n","Epoch 8/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.1227 - acc: 0.9531 - val_loss: 0.9031 - val_acc: 0.7032\n","Epoch 9/20\n","625/625 [==============================] - 8s 12ms/step - loss: 0.1115 - acc: 0.9570 - val_loss: 0.9321 - val_acc: 0.7116\n","Epoch 10/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.1022 - acc: 0.9620 - val_loss: 0.9427 - val_acc: 0.6988\n","Epoch 11/20\n","625/625 [==============================] - 7s 12ms/step - loss: 0.0952 - acc: 0.9645 - val_loss: 0.9515 - val_acc: 0.7042\n","Epoch 12/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0853 - acc: 0.9692 - val_loss: 0.9801 - val_acc: 0.6978\n","Epoch 13/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0828 - acc: 0.9704 - val_loss: 1.0858 - val_acc: 0.6984\n","Epoch 14/20\n","625/625 [==============================] - 7s 12ms/step - loss: 0.0746 - acc: 0.9725 - val_loss: 1.1752 - val_acc: 0.7100\n","Epoch 15/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0699 - acc: 0.9742 - val_loss: 1.2104 - val_acc: 0.7072\n","Epoch 16/20\n","625/625 [==============================] - 7s 12ms/step - loss: 0.0635 - acc: 0.9776 - val_loss: 1.2780 - val_acc: 0.6894\n","Epoch 17/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0586 - acc: 0.9785 - val_loss: 1.2695 - val_acc: 0.6870\n","Epoch 18/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0543 - acc: 0.9796 - val_loss: 1.3574 - val_acc: 0.6730\n","Epoch 19/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0512 - acc: 0.9816 - val_loss: 1.3546 - val_acc: 0.6878\n","Epoch 20/20\n","625/625 [==============================] - 7s 11ms/step - loss: 0.0470 - acc: 0.9836 - val_loss: 1.4282 - val_acc: 0.6728\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"POhP6d5oEbBw"},"source":["# 연습"]},{"cell_type":"code","metadata":{"id":"HoaeBMEeEec0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605960335223,"user_tz":-540,"elapsed":675,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"d5b94c83-1086-49ac-8f11-e12cf2816da7"},"source":["import tensorflow as tf\n","# 문장 토큰화와 단어 토큰화\n","text=[['Hope', 'to', 'see', 'you', 'soon'],['Nice', 'to', 'see', 'you', 'again']]\n","\n","# 각 단어에 대한 정수 인코딩\n","text=[[0, 1, 2, 3, 4],[5, 1, 2, 3, 6]]\n","\n","# 위 데이터가 아래의 임베딩 층의 입력이 된다.\n","embedding_layer = Embedding(7, 2, input_length=5)\n","result = embedding_layer(tf.constant([0, 1, 2, 3, 4, 5, 6]))\n","print(result.numpy())\n","\n","# 7은 단어의 개수. 즉, 단어 집합(vocabulary)의 크기이다.\n","# 2는 임베딩한 후의 벡터의 크기이다.\n","# 5는 각 입력 시퀀스의 길이. 즉, input_length이다. 아래와 같은 형태가 됨.\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[[-0.02118009 -0.00927242]\n"," [ 0.02958209 -0.00727258]\n"," [-0.02273032  0.04170969]\n"," [-0.03339268 -0.00979058]\n"," [-0.046245   -0.01901625]\n"," [ 0.01861269 -0.0196162 ]\n"," [ 0.00043071  0.04945743]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZFOcyZasntE","executionInfo":{"status":"ok","timestamp":1605961097473,"user_tz":-540,"elapsed":658,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"75f07e05-e1aa-43b6-b30b-b59ca0936a1e"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","corpus = ['Hope to see you soon',\n","         'Nice to see you again']\n","cv = CountVectorizer()\n","cv.fit_transform(corpus).toarray() , cv.get_feature_names(), cv.vocabulary_"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[0, 1, 0, 1, 1, 1, 1],\n","        [1, 0, 1, 1, 0, 1, 1]]),\n"," ['again', 'hope', 'nice', 'see', 'soon', 'to', 'you'],\n"," {'again': 0, 'hope': 1, 'nice': 2, 'see': 3, 'soon': 4, 'to': 5, 'you': 6})"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"vPpriV7NEdAv","executionInfo":{"status":"ok","timestamp":1605961366031,"user_tz":-540,"elapsed":698,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}}},"source":["from gensim.models.word2vec import Word2Vec\n","\n","text=[['Hope', 'to', 'see', 'you', 'soon'],\n","      ['Nice', 'to', 'see', 'you', 'again']]\n","\n","model = Word2Vec(text, min_count=1, size=2)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8k8gEguswayh","executionInfo":{"status":"ok","timestamp":1605961664803,"user_tz":-540,"elapsed":668,"user":{"displayName":"Yongjin Jeong","photoUrl":"","userId":"03658406798560557048"}},"outputId":"38a3e433-cc5f-4d5d-d72b-61d31d3a3966"},"source":["for i in range(len(text)):\n","    print(model[text[i]])"],"execution_count":54,"outputs":[{"output_type":"stream","text":["[[ 0.23368882  0.09553892]\n"," [-0.13342807  0.19152431]\n"," [-0.21259055 -0.11372297]\n"," [-0.12717737 -0.15141335]\n"," [ 0.06255915  0.16907026]]\n","[[ 0.0576661  -0.07021116]\n"," [-0.13342807  0.19152431]\n"," [-0.21259055 -0.11372297]\n"," [-0.12717737 -0.15141335]\n"," [-0.16266923  0.08115795]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3MSa403gwWum"},"source":[""],"execution_count":null,"outputs":[]}]}